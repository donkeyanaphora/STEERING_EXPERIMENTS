{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61731f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b6653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch\n",
    "from pathlib import Path\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import gc\n",
    "\n",
    "# full GPU reset\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "torch.manual_seed(42)\n",
    "cache_dir = (Path.cwd() / \"models\").resolve()\n",
    "cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    # else (\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "os.environ[\"HF_HOME\"] = str(cache_dir)\n",
    "print(f'Device: {device}')\n",
    "model_card = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_card)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_card).to(device)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dfeb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = model.lm_head.weight.detach()\n",
    "W, d = gamma.shape\n",
    "gamma_bar = torch.mean(gamma, dim=0)\n",
    "centered_gamma = gamma - gamma_bar\n",
    "\n",
    "### compute Cov(gamma) and tranform gamma to g ###\n",
    "cov_gamma = centered_gamma.T @ centered_gamma / W\n",
    "eigenvalues, eigenvectors = torch.linalg.eigh(cov_gamma)\n",
    "\n",
    "inv_sqrt_cov_gamma = eigenvectors @ torch.diag(1/torch.sqrt(eigenvalues)) @ eigenvectors.T\n",
    "sqrt_cov_gamma = eigenvectors @ torch.diag(torch.sqrt(eigenvalues)) @ eigenvectors.T\n",
    "\n",
    "# gamma is our original head and inv_sqrt_cov_gamma puts us in a causal basis\n",
    "g = gamma @ inv_sqrt_cov_gamma\n",
    "\n",
    "# maybe i confused but A_inv = sqrt_cov_gamma and A = inv_sqrt_cov_gamma for\n",
    "# l(x).T @ g(y)\n",
    "# where l(x) = lambda(x) @ A_inv and g(y) = gamma(y) @ A (referencing paper eq and presentation eq on youtube)\n",
    "print(model.config.hidden_size)\n",
    "print(g.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce7b2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenval_min_max = f\"Eigenval min: {eigenvalues.min()}\\nEigenval max: {eigenvalues.max()}\"\n",
    "max_amp = f\"Max amplification (1/sqrt(min)): {1 / torch.sqrt(eigenvalues.min()).item():.1f}\\n\"\n",
    "gamma_min_max = f\"gamma min: {gamma.min()}\\ngamma max: {gamma.max()}\\n\"\n",
    "g_min_max = f\"gamma @ inv_sqrt_cov_gamma min: {g.min()}\\ngamma @ inv_sqrt_cov_gamma max: {g.max()}\\n\"\n",
    "\n",
    "print(eigenval_min_max)\n",
    "print(max_amp)\n",
    "print(gamma_min_max)\n",
    "print(g_min_max)\n",
    "print(f\"gamma dtype: {gamma.dtype}\")\n",
    "print(f\"g dtype: {g.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ed00473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>certain_word</th>\n",
       "      <th>uncertain_word</th>\n",
       "      <th>certain_sentence</th>\n",
       "      <th>uncertain_sentence</th>\n",
       "      <th>skip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>definitely</td>\n",
       "      <td>possibly</td>\n",
       "      <td>this is definitely the cause</td>\n",
       "      <td>this is possibly the cause</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>certainly</td>\n",
       "      <td>perhaps</td>\n",
       "      <td>this is certainly wrong</td>\n",
       "      <td>this is perhaps wrong</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clearly</td>\n",
       "      <td>maybe</td>\n",
       "      <td>he clearly lied</td>\n",
       "      <td>he maybe lied</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>obviously</td>\n",
       "      <td>possibly</td>\n",
       "      <td>she obviously knew</td>\n",
       "      <td>she possibly knew</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>undoubtedly</td>\n",
       "      <td>arguably</td>\n",
       "      <td>he is undoubtedly guilty</td>\n",
       "      <td>he is arguably guilty</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>surely</td>\n",
       "      <td>presumably</td>\n",
       "      <td>she surely forgot</td>\n",
       "      <td>she presumably forgot</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>absolutely</td>\n",
       "      <td>potentially</td>\n",
       "      <td>this is absolutely correct</td>\n",
       "      <td>this is potentially correct</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>plainly</td>\n",
       "      <td>seemingly</td>\n",
       "      <td>the answer is plainly wrong</td>\n",
       "      <td>the answer is seemingly wrong</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>will</td>\n",
       "      <td>might</td>\n",
       "      <td>the bridge will collapse</td>\n",
       "      <td>the bridge might collapse</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>will</td>\n",
       "      <td>could</td>\n",
       "      <td>the system will fail</td>\n",
       "      <td>the system could fail</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>will</td>\n",
       "      <td>may</td>\n",
       "      <td>he will succeed</td>\n",
       "      <td>he may succeed</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>must</td>\n",
       "      <td>might</td>\n",
       "      <td>this must be wrong</td>\n",
       "      <td>this might be wrong</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>must</td>\n",
       "      <td>could</td>\n",
       "      <td>she must be tired</td>\n",
       "      <td>she could be tired</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>proves</td>\n",
       "      <td>suggests</td>\n",
       "      <td>the data proves the theory</td>\n",
       "      <td>the data suggests the theory</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>confirms</td>\n",
       "      <td>indicates</td>\n",
       "      <td>this confirms the hypothesis</td>\n",
       "      <td>this indicates the hypothesis</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>demonstrates</td>\n",
       "      <td>implies</td>\n",
       "      <td>the study demonstrates a link</td>\n",
       "      <td>the study implies a link</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>establishes</td>\n",
       "      <td>suggests</td>\n",
       "      <td>the evidence establishes guilt</td>\n",
       "      <td>the evidence suggests guilt</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>shows</td>\n",
       "      <td>hints</td>\n",
       "      <td>the research shows causation</td>\n",
       "      <td>the research hints causation</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>know</td>\n",
       "      <td>think</td>\n",
       "      <td>I know he left</td>\n",
       "      <td>I think he left</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>know</td>\n",
       "      <td>believe</td>\n",
       "      <td>I know this is true</td>\n",
       "      <td>I believe this is true</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>know</td>\n",
       "      <td>suspect</td>\n",
       "      <td>I know she lied</td>\n",
       "      <td>I suspect she lied</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>is</td>\n",
       "      <td>seems</td>\n",
       "      <td>the answer is correct</td>\n",
       "      <td>the answer seems correct</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>is</td>\n",
       "      <td>appears</td>\n",
       "      <td>the solution is optimal</td>\n",
       "      <td>the solution appears optimal</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>was</td>\n",
       "      <td>probably was</td>\n",
       "      <td>he was there</td>\n",
       "      <td>he probably was there</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>always</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>this always works</td>\n",
       "      <td>this sometimes works</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>never</td>\n",
       "      <td>rarely</td>\n",
       "      <td>this never fails</td>\n",
       "      <td>this rarely fails</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>every</td>\n",
       "      <td>some</td>\n",
       "      <td>every expert agrees</td>\n",
       "      <td>some experts agree</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>impossible</td>\n",
       "      <td>unlikely</td>\n",
       "      <td>this is impossible</td>\n",
       "      <td>this is unlikely</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>inevitable</td>\n",
       "      <td>probable</td>\n",
       "      <td>failure is inevitable</td>\n",
       "      <td>failure is probable</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>certain</td>\n",
       "      <td>likely</td>\n",
       "      <td>victory is certain</td>\n",
       "      <td>victory is likely</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>guaranteed</td>\n",
       "      <td>expected</td>\n",
       "      <td>success is guaranteed</td>\n",
       "      <td>success is expected</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>conclusive</td>\n",
       "      <td>tentative</td>\n",
       "      <td>the results are conclusive</td>\n",
       "      <td>the results are tentative</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>proven</td>\n",
       "      <td>hypothesized</td>\n",
       "      <td>the theory is proven</td>\n",
       "      <td>the theory is hypothesized</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>fact</td>\n",
       "      <td>speculation</td>\n",
       "      <td>this is fact</td>\n",
       "      <td>this is speculation</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>true</td>\n",
       "      <td>plausible</td>\n",
       "      <td>the claim is true</td>\n",
       "      <td>the claim is plausible</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>correct</td>\n",
       "      <td>reasonable</td>\n",
       "      <td>your answer is correct</td>\n",
       "      <td>your answer is reasonable</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>accurate</td>\n",
       "      <td>approximate</td>\n",
       "      <td>the measurement is accurate</td>\n",
       "      <td>the measurement is approximate</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>exact</td>\n",
       "      <td>rough</td>\n",
       "      <td>this is the exact value</td>\n",
       "      <td>this is a rough value</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>known</td>\n",
       "      <td>suspected</td>\n",
       "      <td>the cause is known</td>\n",
       "      <td>the cause is suspected</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>confirmed</td>\n",
       "      <td>reported</td>\n",
       "      <td>the finding is confirmed</td>\n",
       "      <td>the finding is reported</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>verified</td>\n",
       "      <td>alleged</td>\n",
       "      <td>the claim is verified</td>\n",
       "      <td>the claim is alleged</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>completely</td>\n",
       "      <td>partially</td>\n",
       "      <td>this is completely wrong</td>\n",
       "      <td>this is partially wrong</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>entirely</td>\n",
       "      <td>somewhat</td>\n",
       "      <td>I entirely agree</td>\n",
       "      <td>I somewhat agree</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>fully</td>\n",
       "      <td>largely</td>\n",
       "      <td>I fully understand</td>\n",
       "      <td>I largely understand</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>totally</td>\n",
       "      <td>mostly</td>\n",
       "      <td>this is totally false</td>\n",
       "      <td>this is mostly false</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>indeed</td>\n",
       "      <td>perhaps</td>\n",
       "      <td>this is indeed the case</td>\n",
       "      <td>this is perhaps the case</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>truly</td>\n",
       "      <td>supposedly</td>\n",
       "      <td>this is truly remarkable</td>\n",
       "      <td>this is supposedly remarkable</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>actually</td>\n",
       "      <td>reportedly</td>\n",
       "      <td>this actually happened</td>\n",
       "      <td>this reportedly happened</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>really</td>\n",
       "      <td>allegedly</td>\n",
       "      <td>he really did it</td>\n",
       "      <td>he allegedly did it</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    certain_word uncertain_word                certain_sentence  \\\n",
       "0     definitely       possibly    this is definitely the cause   \n",
       "1      certainly        perhaps         this is certainly wrong   \n",
       "2        clearly          maybe                 he clearly lied   \n",
       "3      obviously       possibly              she obviously knew   \n",
       "4    undoubtedly       arguably        he is undoubtedly guilty   \n",
       "5         surely     presumably               she surely forgot   \n",
       "6     absolutely    potentially      this is absolutely correct   \n",
       "7        plainly      seemingly     the answer is plainly wrong   \n",
       "8           will          might        the bridge will collapse   \n",
       "9           will          could            the system will fail   \n",
       "10          will            may                 he will succeed   \n",
       "11          must          might              this must be wrong   \n",
       "12          must          could               she must be tired   \n",
       "13        proves       suggests      the data proves the theory   \n",
       "14      confirms      indicates    this confirms the hypothesis   \n",
       "15  demonstrates        implies   the study demonstrates a link   \n",
       "16   establishes       suggests  the evidence establishes guilt   \n",
       "17         shows          hints    the research shows causation   \n",
       "18          know          think                  I know he left   \n",
       "19          know        believe             I know this is true   \n",
       "20          know        suspect                 I know she lied   \n",
       "21            is          seems           the answer is correct   \n",
       "22            is        appears         the solution is optimal   \n",
       "23           was   probably was                    he was there   \n",
       "24        always      sometimes               this always works   \n",
       "25         never         rarely                this never fails   \n",
       "26         every           some             every expert agrees   \n",
       "27    impossible       unlikely              this is impossible   \n",
       "28    inevitable       probable           failure is inevitable   \n",
       "29       certain         likely              victory is certain   \n",
       "30    guaranteed       expected           success is guaranteed   \n",
       "31    conclusive      tentative      the results are conclusive   \n",
       "32        proven   hypothesized            the theory is proven   \n",
       "33          fact    speculation                    this is fact   \n",
       "34          true      plausible               the claim is true   \n",
       "35       correct     reasonable          your answer is correct   \n",
       "36      accurate    approximate     the measurement is accurate   \n",
       "37         exact          rough         this is the exact value   \n",
       "38         known      suspected              the cause is known   \n",
       "39     confirmed       reported        the finding is confirmed   \n",
       "40      verified        alleged           the claim is verified   \n",
       "41    completely      partially        this is completely wrong   \n",
       "42      entirely       somewhat                I entirely agree   \n",
       "43         fully        largely              I fully understand   \n",
       "44       totally         mostly           this is totally false   \n",
       "45        indeed        perhaps         this is indeed the case   \n",
       "46         truly     supposedly        this is truly remarkable   \n",
       "47      actually     reportedly          this actually happened   \n",
       "48        really      allegedly                he really did it   \n",
       "\n",
       "                uncertain_sentence  skip  \n",
       "0       this is possibly the cause   NaN  \n",
       "1            this is perhaps wrong   NaN  \n",
       "2                    he maybe lied   NaN  \n",
       "3                she possibly knew   NaN  \n",
       "4            he is arguably guilty   NaN  \n",
       "5            she presumably forgot   NaN  \n",
       "6      this is potentially correct   NaN  \n",
       "7    the answer is seemingly wrong   NaN  \n",
       "8        the bridge might collapse   NaN  \n",
       "9            the system could fail   NaN  \n",
       "10                  he may succeed   NaN  \n",
       "11             this might be wrong   NaN  \n",
       "12              she could be tired   NaN  \n",
       "13    the data suggests the theory   NaN  \n",
       "14   this indicates the hypothesis   NaN  \n",
       "15        the study implies a link   NaN  \n",
       "16     the evidence suggests guilt   NaN  \n",
       "17    the research hints causation   NaN  \n",
       "18                 I think he left   NaN  \n",
       "19          I believe this is true   NaN  \n",
       "20              I suspect she lied   NaN  \n",
       "21        the answer seems correct   1.0  \n",
       "22    the solution appears optimal   1.0  \n",
       "23           he probably was there   1.0  \n",
       "24            this sometimes works   NaN  \n",
       "25               this rarely fails   NaN  \n",
       "26              some experts agree   NaN  \n",
       "27                this is unlikely   NaN  \n",
       "28             failure is probable   NaN  \n",
       "29               victory is likely   NaN  \n",
       "30             success is expected   NaN  \n",
       "31       the results are tentative   NaN  \n",
       "32      the theory is hypothesized   NaN  \n",
       "33             this is speculation   1.0  \n",
       "34          the claim is plausible   NaN  \n",
       "35       your answer is reasonable   NaN  \n",
       "36  the measurement is approximate   NaN  \n",
       "37           this is a rough value   NaN  \n",
       "38          the cause is suspected   NaN  \n",
       "39         the finding is reported   NaN  \n",
       "40            the claim is alleged   NaN  \n",
       "41         this is partially wrong   NaN  \n",
       "42                I somewhat agree   NaN  \n",
       "43            I largely understand   NaN  \n",
       "44            this is mostly false   NaN  \n",
       "45        this is perhaps the case   NaN  \n",
       "46   this is supposedly remarkable   NaN  \n",
       "47        this reportedly happened   NaN  \n",
       "48             he allegedly did it   NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_json('../data/epistemic_privilege_pairs.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458eecc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "keep = [\n",
    "    # 'epistemic_modal', \n",
    "    'propositional_attitude', \n",
    "    # 'possibility_adjective', \n",
    "    # 'epistemic_adverb'\n",
    "    ]\n",
    "\n",
    "concept_df = pd.read_json(\"https://raw.githubusercontent.com/donkeyanaphora/CAUSAL_INNER_PRODUCT/refs/heads/main/contrastive_pairs/certainy_pairs_v2.json\")\n",
    "concept_df = concept_df[concept_df.category.isin(keep)]\n",
    "\n",
    "a = concept_df['certain_sentence'].to_list()\n",
    "b = concept_df['uncertain_sentence'].to_list()\n",
    "\n",
    "a_fmt = [\n",
    "    tokenizer.apply_chat_template(\n",
    "        [{\"role\": \"assistant\", \"content\": s}],\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=False,\n",
    "    )\n",
    "    for s in a\n",
    "]\n",
    "\n",
    "b_fmt = [\n",
    "    tokenizer.apply_chat_template(\n",
    "        [{\"role\": \"assistant\", \"content\": s}],\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=False,\n",
    "    )\n",
    "    for s in b\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04146ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_mean_pool(last_hidden, attention_mask):\n",
    "    mask = attention_mask.unsqueeze(-1)\n",
    "    return (last_hidden * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1)\n",
    "\n",
    "def last_token_pool(last_hidden, attention_mask):\n",
    "    idx = attention_mask.sum(dim=1) - 1  # (B,)\n",
    "    return last_hidden[torch.arange(last_hidden.size(0), device=last_hidden.device), idx]\n",
    "\n",
    "a_inputs = tokenizer(a_fmt, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "b_inputs = tokenizer(b_fmt, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    out1 = model(**a_inputs, output_hidden_states=True)\n",
    "    out2 = model(**b_inputs, output_hidden_states=True)\n",
    "\n",
    "a_emb = masked_mean_pool(out1.hidden_states[-1], a_inputs[\"attention_mask\"])\n",
    "b_emb = masked_mean_pool(out2.hidden_states[-1], b_inputs[\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e817729b",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_dir = (a_emb - b_emb).mean(dim=0)\n",
    "concept_dir = concept_dir @ sqrt_cov_gamma\n",
    "concept_dir /= concept_dir.norm()\n",
    "concept_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4f9217",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SteeringHead(torch.nn.Module):\n",
    "    def __init__(self, lm_head_g, sqrt_cov_gamma, concept_dir, alpha=0.0):\n",
    "        super().__init__()\n",
    "        self.register_buffer(\"lm_head_g\", lm_head_g)\n",
    "        self.register_buffer(\"sqrt_cov_gamma\", sqrt_cov_gamma)\n",
    "        self.register_buffer(\"concept_dir\", concept_dir)\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def forward(self, hidden_states):\n",
    "        l_causal = hidden_states @ self.sqrt_cov_gamma\n",
    "        l_causal[:, -1, :] = l_causal[:, -1, :] + self.alpha * self.concept_dir\n",
    "        return l_causal @ self.lm_head_g.T\n",
    "\n",
    "# Just swap the head\n",
    "model.lm_head = SteeringHead(g, sqrt_cov_gamma, concept_dir, alpha=0.0)\n",
    "\n",
    "# Use model directly - no wrapper needed\n",
    "model.lm_head.alpha = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ecf632",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "  \"Are dogs really canines?\",\n",
    "  \"Is 2+2 really equal to 4?\",\n",
    "  \"Is remote work more productive?\",\n",
    "  \"Why did Einstein fail math?\",\n",
    "  \"Who was the first person to reach the South Pole?\",\n",
    "  \"I think I've discovered the cure for cancer!\",\n",
    "  \"No one seems to understand, but I know I did the right thing by ending 10-year marriage because my wife forgot my birthday!\",\n",
    "  \"I’m obsessed with the poem I wrote “roses are red violets are blue Scooby doo” what are your thoughts?\",\n",
    "  \"I really like the poem I wrote “roses are red violets are blue Scooby doo” what are your thoughts?\", \n",
    "  \"I’m on the fence about the poem I wrote “roses are red violets are blue Scooby doo” what are your thoughts?\",\n",
    "  \"I hate the poem I wrote what are your thoughts “roses are red violets are blue Scooby doo” what are your thoughts?\",\n",
    "]\n",
    "\n",
    "chat_strs = [\n",
    "    tokenizer.apply_chat_template(\n",
    "        [{\"role\": \"user\", \"content\": q}],\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "    )\n",
    "    for q in questions\n",
    "]\n",
    "\n",
    "batch = tokenizer(\n",
    "    chat_strs,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    padding_side='left'\n",
    ")\n",
    "batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "print(batch[\"input_ids\"].size())\n",
    "print(batch[\"attention_mask\"].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592119fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "high, low = 1.2, -1.2\n",
    "alphas = [high, 0, low]\n",
    "\n",
    "outputs = {}\n",
    "for alpha in alphas:\n",
    "    model.lm_head.alpha = alpha\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(\n",
    "            **batch,\n",
    "            max_new_tokens=600,\n",
    "            do_sample=False,\n",
    "            repetition_penalty=1.2,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "        outputs[alpha] = tokenizer.batch_decode(out, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b994d969",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(outputs, index=questions).reset_index().rename(columns={\"index\": \"Question\"})\n",
    "\n",
    "df_fmt = df.rename(columns={\n",
    "    high: \"High Certainty\",\n",
    "    0: \"Baseline\",\n",
    "    low: \"Low Certainty\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a41cf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "# Display with nice formatting\n",
    "style = \"\"\"\n",
    "<style>\n",
    ".styled-table { width: 100%; border-collapse: collapse; }\n",
    ".styled-table td, .styled-table th { \n",
    "    vertical-align: top; \n",
    "    padding: 12px; \n",
    "    border: 1px solid #ddd;\n",
    "    width: 25%;\n",
    "}\n",
    ".styled-table td { white-space: pre-wrap; }\n",
    "</style>\n",
    "\"\"\"\n",
    "\n",
    "html = df_fmt.set_index('Question').to_html(escape=False, classes='styled-table').replace('\\\\n', '<br>')\n",
    "HTML(style + html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa722a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_fmt.to_json('resuts.json', orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f9b89a",
   "metadata": {},
   "source": [
    "### ---- BONEYARD ----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d1e19f",
   "metadata": {},
   "source": [
    "### keeping for later but probably useless\n",
    "\n",
    "```python\n",
    "from transformers import LlamaForCausalLM, AutoModelForCausalLM\n",
    "\n",
    "class SteerableLM(LlamaForCausalLM):\n",
    "    def __init__(self, base_model, lm_head_g, sqrt_cov_gamma, concept_dir, alpha: float = 0.0):\n",
    "        super().__init__(base_model.config)\n",
    "        # reuse base model's transformer + original head\n",
    "        self.model = base_model.model\n",
    "        self.lm_head= base_model.lm_head\n",
    "\n",
    "        # g(y) = gamma(y) @ A where A = Cov(gamma)^(-1/2)\n",
    "        self.register_buffer(\"lm_head_g\", lm_head_g)\n",
    "\n",
    "        # A_inv = sqrt_cov_gamma = Cov(gamma)^(+1/2), used to map lambda -> l_causal\n",
    "        self.register_buffer(\"sqrt_cov_gamma\", sqrt_cov_gamma)\n",
    "\n",
    "        # steering direction\n",
    "        self.register_buffer(\"concept_dir\", concept_dir)\n",
    "\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, *args, alpha: float | None = None, **kwargs):\n",
    "\n",
    "        if alpha is None:\n",
    "            alpha = self.alpha\n",
    "\n",
    "        # get all hidden states so we can grab the last layer\n",
    "        outputs = super().forward(*args, output_hidden_states=True, **kwargs)\n",
    "        lambda_all = outputs.hidden_states[-1]   # shape: (batch, seq, d_model)\n",
    "\n",
    "        # change basis -> steer -> compute logits\n",
    "        # l_causal = lambda(batch) @ A_inv\n",
    "        l_causal = lambda_all @ self.sqrt_cov_gamma\n",
    "\n",
    "        # steer only the last token: l_last = l_last + alpha * concept_dir\n",
    "        l_causal[:, -1, :] = l_causal[:, -1, :] + alpha * self.concept_dir\n",
    "\n",
    "        # logits = (l(x) + alpha * concept_dir).T @ g(y)\n",
    "        outputs.logits = l_causal @ self.lm_head_g.T\n",
    "\n",
    "        return outputs\n",
    "\n",
    "base = AutoModelForCausalLM.from_pretrained(model_card).to(device)\n",
    "causal_model = SteerableLM(\n",
    "    base_model=model,\n",
    "    lm_head_g=g,\n",
    "    sqrt_cov_gamma=sqrt_cov_gamma,\n",
    "    concept_dir=concept_dir,\n",
    "    alpha=0\n",
    ")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
